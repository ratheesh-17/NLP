{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1b01e2-5284-47be-96f6-18c07cfec3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Download the “en_core_web_sm” model for spaCy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ce7209-c84f-4a49-8ed9-59af88613400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy package and load the spaCy model: “en_core_web_sm”.\n",
    "import spacy                                  # Import spaCy library\n",
    "nlp = spacy.load(\"en_core_web_sm\")            # load spaCy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6a42d1-74ce-4ae6-93a8-7851ad628c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the “English” library.\n",
    "from spacy.lang.en import English                              # Importing library\n",
    "nlp = English()                                                # Importing model\n",
    "nlp = spacy.load(\"en_core_web_sm\")                             # Importing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb42c3d-2718-426a-85ee-5802ec257676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer service was excellent at the store. The manager has helped me at checkout. My friend has been shopping at this location for years. The staff has always been friendly.\n"
     ]
    }
   ],
   "source": [
    "# Read the input data file and display first 5 lines.\n",
    "filename = r\"C:\\Users\\91934\\Downloads\\Sample.txt\"\n",
    "with open(filename, \"r\") as file:\n",
    "\n",
    "  contents = file.read()\n",
    "# Print first 5 lines\n",
    "\n",
    "for line in contents.splitlines()[:5]:\n",
    "\n",
    "  print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2abfe937-aaab-4ba0-941c-c4dae162b517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The, customer, service, was, excellent, at, the, store, ., The]\n"
     ]
    }
   ],
   "source": [
    "# Convert file contents to text, tokenize with NLP, and print few tokens\n",
    "text_combined = str(contents)                                  # String\n",
    "doc = nlp(text_combined)                                       # Create NLP object\n",
    "print([token for token in doc[:10]])                           # Print first 10 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ebcc206-9f6b-473c-a6c2-85cb8972a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 4), ('The', 3), ('at', 3), ('has', 3), ('been', 2), ('customer', 1), ('service', 1), ('was', 1), ('excellent', 1), ('the', 1), ('store', 1), ('manager', 1), ('helped', 1), ('me', 1), ('checkout', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Extract the frequency of word count.\n",
    "from collections import Counter\n",
    "freq_counts = Counter()\n",
    "for token in doc:\n",
    "\n",
    "  freq_counts[token.orth_] += 1                       # Equivalently, token.text\n",
    "\n",
    "# Print the most common words from the input text.\n",
    "most_common_words = freq_counts.most_common(15)             # Most common words in document\n",
    "print(most_common_words)                                      # To print the frequency count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e11fffaf-295d-4ef5-9fae-62bb46cb5a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', '’ll', 'meet', 'at', '5:00', 'PM', '.']\n"
     ]
    }
   ],
   "source": [
    "# Perform tokenization for following sentences:\n",
    "'''\n",
    "Alice's book was on the table.\n",
    "He said, 'Hello there!’\n",
    "We’ll meet at 5:00 PM.\n",
    "'''\n",
    "sentences = [\n",
    "    \"Alice's book was on the table.\",\n",
    "    \"He said, 'Hello there!’\",\n",
    "    \"We’ll meet at 5:00 PM.\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "\n",
    "  doc = nlp(s)\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e7b13-7872-4b0c-bd56-2a488fa3de3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
