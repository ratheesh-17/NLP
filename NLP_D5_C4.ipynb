{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0db88-404e-40a4-bfce-5d1d71ff9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import spacy\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def main():\n",
    "    # Get filename from user\n",
    "    \n",
    "    file_path = r\"C:\\Users\\91934\\Downloads\\Sample.txt\"\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Load spaCy model\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        print(\"SpaCy model 'en_core_web_sm' not found. Install it using:\")\n",
    "        print(\"python -m spacy download en_core_web_sm\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Initialize stemmer\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    \n",
    "    # Read the file content\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # 1. Display original text sample (first 300 characters)\n",
    "    print(\"Original Text Sample:\")\n",
    "    print(content[:300])\n",
    "    print()\n",
    "    \n",
    "    # 2. Lemmatization: Individual Words (Demo 6.2.1)\n",
    "    print(\"=== Lemmatization: Individual Words ===\")\n",
    "    sample_words = \"friendship studied was am is organizing matches\"\n",
    "    doc_sample = nlp(sample_words)\n",
    "    for token in doc_sample:\n",
    "        if not token.is_space:\n",
    "            print(f\"{token.text} -> {token.lemma_}\")\n",
    "    print()\n",
    "    \n",
    "    # 3. Stemming: Individual Words (Demo 6.2.2)\n",
    "    print(\"=== Stemming: Individual Words ===\")\n",
    "    sample_words_list = sample_words.split()\n",
    "    for word in sample_words_list:\n",
    "        stem = stemmer.stem(word)\n",
    "        print(f\"{word} --> {stem}\")\n",
    "    print()\n",
    "    \n",
    "    # 4. Lemmatization: Full Text (Demo 6.2.3)\n",
    "    print(\"=== Lemmatization: Full Text ===\")\n",
    "    doc_full = nlp(content)\n",
    "    tokens_full = [token for token in doc_full if not token.is_space]\n",
    "    for token in tokens_full[:50]:\n",
    "        print(f\"{token.text} --> {token.lemma_}\")\n",
    "    print()\n",
    "    \n",
    "    # 5. Stemming: Full Text (Demo 6.2.4)\n",
    "    print(\"=== Stemming: Full Text ===\")\n",
    "    for token in tokens_full[:50]:\n",
    "        stem = stemmer.stem(token.text.lower())\n",
    "        print(f\"{token.text} --> {stem}\")\n",
    "    print()\n",
    "    \n",
    "    # 6. Practice Comparison Table (Practice 6.2)\n",
    "    print(\"=== Practice 6.2: Lemmatization vs Stemming ===\")\n",
    "    print(\"Word\\t\\tLemma\\t\\tStem\")\n",
    "    print(\"------------------------------------------\")\n",
    "    practice_words = \"running good universities flies fairer is\"\n",
    "    doc_practice = nlp(practice_words)\n",
    "    practice_tokens = [token for token in doc_practice if not token.is_space]\n",
    "    \n",
    "    for token in practice_tokens:\n",
    "        lemma = token.lemma_\n",
    "        stem = stemmer.stem(token.text.lower())\n",
    "        print(f\"{token.text}\\t\\t{lemma}\\t\\t{stem}\")\n",
    "    print()\n",
    "    \n",
    "    # 7. Conclusion\n",
    "    print(\"Conclusion:\")\n",
    "    print(\"Lemmatization produces dictionary-based meaningful root words, while stemming may distort words by chopping suffixes. For NLP tasks like search, topic modeling, and information retrieval, lemmatization gives better and cleaner output.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816d302-7a9d-4c43-8030-0ab802e570fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
